---
title: "Computer Assignment 1"
author: "Will Dziuk and Andri Þór Stefánson"
date: "2025-11-20"
output: pdf_document
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Exercise 1:1

```{r}
abortion_data <- data.frame(
    sex = c("Male","Female"),
    in_favor = c(319,309),
    against = c(281,191)

)
print(abortion_data)
```

## 1.

```{r}
#Men in favor
p_11 <- abortion_data[1,2]/(abortion_data[1,2] + abortion_data[1,3])
#Men against
p_12 <- abortion_data[1,3]/(abortion_data[1,2] + abortion_data[1,3])
#Women in favor
p_21 <- abortion_data[2,2]/(abortion_data[2,2] + abortion_data[2,3])
#Women against
p_22 <- abortion_data[2,3]/(abortion_data[2,2] + abortion_data[2,3])

p_11
p_12
p_21
p_22
```

## 2.

We define the null hypothesis as $H_0: p_{1,1} = p_{2,1}$ and the
alternative hypothesis as $H_a: p_{1,1} \neq p_{2,1}$

Pearson's $\chi^2$ statistic: $X^2 = \sum_{i,j} \frac{(N_{ij} - \hat \mu_{ij})^2}{\hat \mu_{ij}}$
Where

\-$p_{i+} = \sum_j \frac{O_{i,j}}{N}$

\- $p_{+j} = \sum_i \frac{O_{i,j}}{N}$

\-$O_{i,j}$ is the observed cell count.

\- $N$ is the total sample size.

Likelihood Ratio Test
$G^2 = -2\ln \frac{\text{sup}_{H_a}l(p_0)}{\text{sup}_{H_0}l(p_1, p_2)} = -2(n_{+1}\ln(\frac{n_{+1}}{N}) + n_{+2}\ln(\frac{n_{+2}}{N})) + 2(\sum_{ij} n_{ij} \ln(\frac{n_{ij}}{\hat \mu_{ij}}))$

We reject the null hypothesis if $p(X^2 > \chi^2_1) < \alpha$ for the
Pearson's $\chi^2$ test and if $p(G^2 > \chi^2_1) < \alpha$ for the
Likelihood ratio test.

Let's do a Pearson's $\chi^2$ test with $\alpha = 0.05$.

```{r}
pearsons_test <- 0
n = abortion_data[1,2] + abortion_data[1,3] + abortion_data[2,2] + abortion_data[2,3]
for (i in 1:2){
  n_i <- abortion_data[i, 2] + abortion_data[i,3]
  for (j in 2:3){
    n_ij <- abortion_data[i,j]
    n_j <- abortion_data[1, j] + abortion_data[2, j]
    mu_ij = n_i * n_j / n
    pearsons_test = pearsons_test + (n_ij - mu_ij)^2/mu_ij
  }
}
pearsons_test
1 - pchisq(pearsons_test, df = 1)
```

So we reject $H_0$ at level $\alpha = 0.05$ using the Pearson's Test.

Now we do the Likelihood ratio test.

```{r}
LR_test <- 0
n = abortion_data[1,2] + abortion_data[1,3] + abortion_data[2,2] + abortion_data[2,3]
for (i in 1:2){
  n_i <- abortion_data[i, 2] + abortion_data[i,3]
  for (j in 2:3){
    n_ij <- abortion_data[i,j]
    n_j <- abortion_data[1, j] + abortion_data[2, j]
    mu_ij = n_i * n_j / n
    LR_test = LR_test + 2* n_ij * log(n_ij / mu_ij)
  }
}
LR_test
1 - pchisq(LR_test, df = 1)
```

We would also reject the null hypothesis using the Likelihood ratio
test.

## 3.

Odds Ratio (between males and females):
$\hat\theta = \frac{n_{11}n_{22}}{n_{12}n_{21}}$

95% Confidence Interval for $\log(\hat\theta)$:
$[\log(\hat\theta) - 1.96 \cdot SE , \log(\hat\theta) + 1.96 \cdot SE] = [a,b]$

Where
$SE = \sqrt{Var[\log(\hat\theta)]} = \sqrt{\frac{1}{n_{11}} + \frac{1}{n_{12}} + \frac{1}{n_{21}} + \frac{1}{n_{22}}}$

So the 95% confidence interval for $\theta$ is $[e^a, e^b]$

```{r}
n_11 <- abortion_data[1,2]
n_12 <- abortion_data[1,3]
n_21 <- abortion_data[2,2]
n_22 <- abortion_data[2,3]

theta_hat <- (n_11*n_22) / (n_12*n_21)

SE <- sqrt(1/n_11 + 1/n_21 + 1/n_12 + 1/n_22)

log_lower <- log(theta_hat) - 1.96*SE
log_upper <- log(theta_hat) + 1.96*SE

ci <- c(exp(log_lower), exp(log_upper))
theta_hat
ci
```

According to this, the odds of men being in favor of abortion is $0.7$
times that of women. Our confidence interval tells us that the true odds
ratio lies between $0.55$ and $0.89$ with 95% confidence.

## 4

The risk ratio: $\hat{r}=\frac{n_{11}n_{2+}}{n_{21}n_{1+}}$

The confidence interval for
$\log(\hat{r}) = [\log(\hat r ) - 1.96 \cdot SE , \log(\hat r) + 1.96 \cdot SE] = [a,b]$

Where
$SE = \sqrt{Var(\log(\hat r))} = \sqrt{\frac{1-n_{11}/n_{1+}}{n_{11}} + \frac{1-n_{21}/n_{2+}}{n_{21}}}$

So the 95% confidence interval for $\hat r$ is $[e^a, e^b]$

```{r}
n_1 <- n_11 + n_12
n_2 <- n_21 + n_22

r_hat <- n_11*n_2 / (n_21*n_1)

SE <- sqrt((1-n_11/n_1)/n_11 + (1-n_21/n_2)/n_21)

log_lower <- log(r_hat) - 1.96*SE
log_upper <- log(r_hat) + 1.96*SE

ci <- c(exp(log_lower), exp(log_upper))
r_hat
ci
```

According to this, the risk of men being in favor of abortion is $0.86$
times that of women. Our confidence interval tells us that the true risk
ratio lies between $0.78$ and $0.95$ with 95% confidence.

## 5

Now we will use the built in R functions to calculate the values and
statistics from questions 1-4.

```{r}
tab1<- as.table(rbind(c(309, 191), c(319, 281)))
dimnames(tab1) <- list(gender = c("women", "men"),opinion = c("favor","against"))
addmargins(tab1)
addmargins(prop.table(tab1,1),2)
```

We can see that the probabilities match what we had found in question 1.

Calculate $X^2$, $G^2$ and p-values

```{r}
chisq.test(tab1,correct=FALSE)
library(MASS)
loglm(~gender+opinion,tab1)
```

Again we can see that the test statistics and p-values match what we had
found above.

Now we calculate risk/odds ratio and confidence interval using R
functions

```{r}
library(epitools)
oddsratio(tab1, method = "wald", rev="col")
riskratio(tab1,rev="col")

```

We can see that the ratios and confidence intervals match what we have
found in questions 3 and 4

# Exercise 1:2

## 1

```{r}
tab2<- as.table(rbind(c(1198, 1493), c(557, 1278)))
dimnames(tab2) <- list(gender = c("men", "women"),result = c("Admitted","Rejected"))
addmargins(tab2)
addmargins(prop.table(tab2,1),2)
```

We are performing the Pearson's test and Likelihood ratio test to
compare the probability of admission for men vs women. Our null
hypothesis is $H_0: p_{1,1} = p_{2,1}$ and our alternative Hypothesis is
$H_a: p_{1,1} \neq p_{2,1}$. We will use $\alpha = 0.05$

```{r}
loglm(~gender+result,tab2)
```

As seen above the p-values from these tests are very small. Therefore we
reject the null hypothesis.

Now we will calculate the odds ratio between the admission of men and
women.

```{r}
oddsratio(tab2, method = "wald")
```

The odds ratio that we calculated here is the odds of women being rejected is $1.84108$ times that of men. The $95\%$
confidence interval $[1.624377 , 2.086693]$.

Now we will calculate the risk ratio, between the admission probability
of men to that of women.

```{r}
riskratio(tab2)
```
From this we see that the probability of women being rejected is $1.255303$
times as high as for men, with the confidence interval being
$[1.199631 , 1.31356]$.

## 2

```{r}
tab3 <- round(tab2/10.0)
loglm(~gender+result,tab3)
```

It seems that dividing the cell counts by 10 divides the statistics by
10. Because we rounded the table to the nearest integer, this does not
perfectly divide by 10.

```{r}
oddsratio(tab3)
riskratio(tab3)
```

The risk ratio and odds ratio stay the same. In this case, there are
small differences because we rounded our table.
The confidence interval for the odds ratio goes from $[1.624377, 2.086693]$ to $[1.239821, 2.741141]$, that is, it grows larger.
And the confidence interval for the risk ratio goes from $[1.199631, 1.31356]$ to $[1.087858, 1.44992]$.

Now we repeat this by dividing by $100$

```{r}
tab4 <- round(tab2/100)
loglm(~gender+result,tab4)
```

The test statistics have been divided by 100, of course with some
rounding errors. With this, the p-value increases.

```{r}
oddsratio(tab4)
riskratio(tab4)
```

The odds and risk ratios stay the same, with some rounding errors.
The confidence interval for the odds ratio grows even more from $[1.624377, 2.086693]$ to $[0.4972715, 6.243172]$, and the confidence interval for the risk ratio grows as well, from $[1.199631, 1.31356]$ to $[0.7812776, 1.941418]$.

## 3

We saw in the earlier task, that scaling all data in a table will scale
the test statistic in the same way, while keeping the odds ratio the
same.

We can use this information to create a table, with an odds ratio close
to 1, but where the odds ratio significantly differs from 1.

This is done by using a large sample size, where the ratios between
groups are relatively close, but still differ slightly.

```{r}
tab5<- as.table(rbind(c(1000000, 1000000), c(1006000, 1000000)))
dimnames(tab5) <- list(gender = c("women", "men"),opinion = c("Admitted","Rejected"))
addmargins(tab5)
addmargins(prop.table(tab5,1),2)
```

```{r}
oddsratio(tab5,rev = "col")
loglm(gender~opinion, data=tab5)
```

In this scenario, we see that the odds ratio is $1.00601$, but the p-value
for the null hypothesis: $H_0: p_{1,1} = p_{1,2}$ is $0.0001267770$ in the Pearson test and $0.0001267753$ in the likelihood ratio test, indicating that the effect of gender on the admission is statistically significant.

While the effect is statistically significant, wording it like that can
be misleading, as it suggests that there is an **important**
association, while in reality the effect is trivial.

In a case like this, we would report the odds ratio, along with the
confidence interval, which we can see is $[1.002073, 1.009966]$. This tells
that the ratio is indeed very close to 1, but not exactly 1, while if we
had only looked at the p-value, we might assume that the odds ratio is
not close to 1.
