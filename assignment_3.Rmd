---
title: "assignment 3"
author: "Andri Þór Stefánsson & Will Dziuk"
date: "2025-12-05"
output: html_document
---
### 1. Fitting models
We start by reading in the data, creating a saturated model, and showing the summary.
```{r echo=FALSE}
setwd("~/projects/uni/categorical_data_analysis/Categorical-Data-Analysis-CA1")
data3<-read.csv("data_ca3.csv")
# Saturated model:
msat<-glm(n~x*y*z*v, family=poisson(link=log), data=data3)
```


```{r}
summary(msat)
```
Since we start by removing higher order terms before moving on to lower order terms, we can see that the x:y:z:v term has a very large p-value, and can therefore be removed.

So now we try a model with the formula: n~(x+y+z+v)^3
```{r}
m1<-glm(n~(x+y+z+v)^3, family=poisson(link=log), data=data3)
summary(m1)
```
From this we can see that none of the 3rd order terms are statistically significant, so we remove all of them.
Now we look at a model with the formula: n~(x+y+z+v)^2.
```{r}
m2<-glm(n~(x+y+z+v)^2, family=poisson(link=log), data=data3)
summary(m2)
```

Here, we see that the second order terms y:z and y:v are statistically insignificant, and x:z has low significance.
```{r echo=FALSE}
m3 <- glm(n~x*y+x*v+x*z+z*v, family=poisson(link=log), data=data3)
m4 <- glm(n~x*y+x*z+z*v, family=poisson(link=log), data=data3)
m5 <- glm(n~x+y+z+v, family=poisson(link=log), data=data3)
```


From this, we can create a table:
```{r echo=FALSE}
library(knitr)
models <- c("XYZV", "(X+Y+Z+V)^3", "(X+Y+Z+V)^2", "XY, XV, XZ, ZV", "XY, XZ, ZV", "X, Y, Z, V")
models_to_check <- list(m1, m2, m3, m4, m5)
i <- 2
deviance <- c(0)
df <- c(0)
p_value <- c(1)
aic <- c(AIC(msat))
for (model in models_to_check){
  anova_res <- anova(msat, model, test="LRT")
  deviance[i] <- anova_res$`Resid. Dev`[2]
  df[i] <- anova_res$Df[2]
  p_value[i] <- anova_res$`Pr(>Chi)`[2]
  aic[i] <- AIC(model)
  i <- i+1
}
results <- data.frame(models, deviance, df, p_value, aic)
kable(results)
```

### 2. Selecting a model
To select a model to use, we can look at the AIC, where lower AIC is better.
In our case, the model with the lowest AIC is m3=(XY, XV, XZ, ZV).
We decided to choose the model with the lowest AIC.

### 3. 
```{r}
summary(m3)
```


The significant associations are:
  - x:y (Mother's age : Smoking habits)
  - x:v (Mother's age : Child survival)
  - x:z (Mother's age : Gestational age)
  - v:z (Child survival : Gestational age)
  
We can see that the interaction term for x:y has an estimate of $-0.40431$ means that 
the log odds ratio of smoking given mother's age are $-0.40431$.
That is,
$$\theta(smoking|mothers\_age \ge 30) = e^{-0.40431} \cdot \theta(smoking|mothers\_age < 30)$$
where $\theta$ is the odds.

This also goes the other way around, that is:

$$\theta(mothers\_age \ge 30 | smoking) = e^{-0.40431} \cdot \theta(mothers\_age < 30 | smoking)$$

In a similar way, we see that the log odds ratio for child survival given mother's age are $-0.44752$, so the odds ratio is $e^{-0.44752}$.

And the log odds ratio for the mother's age given gestational age is $-0.16557$.

And the last interaction term is the log odds ratio for gestation age given child's survival, which is equal to the log odds ratio for child's survival given gestation age is $3.31135$, so the odds ratio is $e^{3.31135}$.

The $95\%$ confidence intervals can be calculated using $CI = [\hat \beta - z_{0.975} \cdot SE, \hat \beta + z_{0.975} \cdot SE]$, so using the standard errors in the summary, we get the following table.
```{r echo=FALSE}
b1 <- -0.40431
b2 <--0.44752
e1 <- 0.09936
e2 <- 0.17963

ci1_l <- b1 - qnorm(0.975)*e1
ci2_l <- b2 - qnorm(0.975)*e2
ci1_u <- b1 + qnorm(0.975)*e1
ci2_u <- b2 + qnorm(0.975)*e2

interaction <- c("xy", "xv", "xz", "vz")
beta_ml <- c(-0.40431, -0.44752, -0.16557, 3.31135)
beta_lower <- c(ci1_l, ci2_l, -0.35370694, 2.949697)
beta_upper <- c(ci1_u, ci2_u, 0.02256694, 3.673003)
odds_ratio_lower <- exp(beta_lower)
odds_ratio_upper <- exp(beta_upper)
results_2 <- data.frame(interaction, beta_ml, beta_lower, beta_upper, odds_ratio_lower, odds_ratio_upper)
kable(results_2)
```

## 4

In order to choose our preferred model n~x+y+z we performed the same steps as in question 1. Our model has no interactions, only the single variables. This is interpreted as Child Survival only being impacted by gestational age, age, and smoking habits individually. 
```{r}
logistic_model<- glm(v~ x+y+z, data = data3,family=binomial(link=logit), weights = n)

summary(logistic_model)

```

From the summary we can see that smoking habits is not statistically significant, however its inclusion creates a better model, this can be seen by it lowering the AIC value when included. 


## 5.
The corresponding log-linear model would have the formula $n \sim x*y*z + v*(x+y+z)$
```{r}
loglin_model <- glm(
  n ~ x * y * z + v * (x + y + z),
  family = poisson(link = "log"),
  data = data3
)
```


```{r echo=FALSE,}
print("logistic model:")
summary(logistic_model)$coef
print("log linear model:")
summary(loglin_model)$coef
```

Here we see the coefficients from both models.
If we compare coefficients x, y, z from the logistic model to the coefficients: x:v, y:v, z:v, we can see that they have the same estimate and std. Error.

